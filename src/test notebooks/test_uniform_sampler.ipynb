{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically a notebook to test code interactively before writing it in full detail in `src/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler\n",
    "\n",
    "\n",
    "random.seed(226)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classwise Uniform Sampler\n",
    "\n",
    "The goal is to write the sampling strategy of randomly pick among the K classes, and randomly pick P examples from these K classes in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, xs,ys):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        \n",
    "        assert len(self.xs) == len(self.ys)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.xs[i], self.ys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = MyDataset(list(range(101,126)), [0,0,0,0,0, 1,1,1,1,1,2,2,2,2,2,3,3,3, 3,3, 4,4, 4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_indices = {x : 5 * x for x in range(5)} #index of first entry of that class\n",
    "num_examples = {x : 5 for x in range(5)} #number of examples for each label\n",
    "\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to handle a K * P batch. What about test time? Train/validation ? Does validation have the sample sample strategy? It should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "P = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 2, 2, 0, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(list(range(5)), k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from loguru import logger\n",
    "\n",
    "log = logger.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassUniformBatchSampler(Sampler):\n",
    "    \"\"\"Returns the classes in order, but with the entries of each class shuffled.\"\"\"\n",
    "    def __init__(self, dataset, P, K, num_classes=num_classes, \n",
    "                 start_indices=start_indices, num_examples=num_examples):\n",
    "        \"\"\"Returns batches of size P x K where P is the number of classes per batch and K is the number of samples per class.\"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.start_indices = start_indices\n",
    "        self.num_examples = num_examples \n",
    "        self.dataset = dataset\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        #log(f\"P = {P}, K = {K}, len(dataset) = {len(dataset)}\")\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Provides a valid permutation of the indices for the dataset.\"\"\"\n",
    "        \n",
    "        #Shuffle indices of each class in place.\n",
    "        classwise_shuffled_indices = []\n",
    "        k_at_time = defaultdict(list) #for each class we want the value to be [[k samples], [k samples], ...]\n",
    "        #log(f\"Before for loop in __iter__, num_classes = {num_classes}\")\n",
    "        for i in range(num_classes):\n",
    "            class_batches = []\n",
    "            start_idx = self.start_indices[i]\n",
    "            stop_idx = start_idx + self.num_examples[i]\n",
    "            #log(f\"For class {i}, start_idx = {start_idx} and stop_idx = {stop_idx}\")\n",
    "            #want a random shuffle of the dataset from start_idx -> start_idx + num_examples\n",
    "            shuffled_examples = random.sample(range(start_idx, stop_idx), stop_idx - start_idx)\n",
    "            #log(f\"For class {i}, shuffled_examples = {shuffled_examples}\")\n",
    "            split_batches = list(torch.split(torch.tensor(shuffled_examples), self.K))\n",
    "            #log(f\"For class {i}, split_batches start = {split_batches}\")\n",
    "            #last_batch = n % self.K\n",
    "            \n",
    "            #we want last batch to also have size K using random.choices\n",
    "            split_batches[-1] = torch.tensor(random.choices(shuffled_examples[-(len(shuffled_examples) % self.K) :], k=self.K))\n",
    "             #we want to pop() elements so the last batch should be at index 0\n",
    "            #log(f\"For class {i}, split_batches after resizing last element = {split_batches}\")\n",
    "            split_batches = split_batches[::-1]\n",
    "            k_at_time[i] = [x.tolist() for x in split_batches] #each is a list of k indices.\n",
    "            #log(f\"For class {i}, k_at_time[i] = {k_at_time[i]}\")\n",
    "            classwise_shuffled_indices += shuffled_examples\n",
    "            \n",
    "        log(f\"k_at_a_time = {k_at_time}\")\n",
    "        \n",
    "        #We want to extract P classes at a time randomly and pop the k_at_a_time[idx] for each\n",
    "        #If any class becomes empty, we want to remove it from our set of alive classes.\n",
    "        #When we have fewer than K classes remaining, we just return what remains.\n",
    "        \n",
    "        alive_classes = set(range(num_classes))\n",
    "        \n",
    "        while len(alive_classes) >= self.P:\n",
    "            #sample P classes\n",
    "            #log(f\"In while loop, alive_classes = {alive_classes}\")\n",
    "            selected_indices = random.sample(list(alive_classes), k=self.P)    \n",
    "            x_batch  = []\n",
    "            \n",
    "            \n",
    "            for idx in selected_indices:\n",
    "                class_batch = k_at_time[idx].pop()\n",
    "                if not k_at_time[idx]:\n",
    "                    alive_classes.remove(idx)\n",
    "                x_batch += class_batch\n",
    "                #y_batch += [idx] * len(class_batch)\n",
    "                \n",
    "            \n",
    "            random.shuffle(x_batch)\n",
    "            #log(f\"In while loop, x_batch = {x_batch}\")\n",
    "            yield x_batch\n",
    "        \n",
    "        #if there are fewer than P classes remaining, we will just cycle through each class and add a set of K elements in order\n",
    "        #until we hit PxK elements. If we are done before we hit PxK elements, we ignore the batch. \n",
    "        log(f\"alive_classes = {alive_classes}\")\n",
    "        curr_batch = []\n",
    "        num_items_in_batch = 0\n",
    "        while len(alive_classes) >= 2: #if there is only one alive class, no point having a triplet loss\n",
    "            for idx in list(alive_classes):\n",
    "                class_batch = k_at_time[idx].pop()\n",
    "                if not k_at_time[idx]:\n",
    "                    alive_classes.remove(idx)\n",
    "                \n",
    "                curr_batch += class_batch\n",
    "                num_items_in_batch += self.K\n",
    "            \n",
    "                if num_items_in_batch == self.P * self.K:\n",
    "                    random.shuffle(curr_batch)\n",
    "                    yield curr_batch\n",
    "                    curr_batch = []\n",
    "                    num_items_in_batch = 0\n",
    "                    \n",
    "        #there are fewer than PxK elements remaining    \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysampler = ClassUniformBatchSampler(dataset=mydataset, P=2, K=2) #each batch has 4 elements from 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 13:46:35.394 | INFO     | __main__:__iter__:43 - k_at_a_time = defaultdict(<class 'list'>, {0: [[0, 0], [3, 2], [1, 4]], 1: [[8, 8], [7, 9], [6, 5]], 2: [[13, 13], [11, 10], [14, 12]], 3: [[17, 17], [18, 15], [16, 19]], 4: [[21, 21], [22, 24], [23, 20]]})\n",
      "2022-11-18 13:46:35.394 | INFO     | __main__:__iter__:72 - alive_classes = {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In batch 0: \n",
      " indices = [4, 1, 12, 14] \n",
      " elements = [(105, 0), (102, 0), (113, 2), (115, 2)] \n",
      "\n",
      "\n",
      "In batch 1: \n",
      " indices = [11, 23, 20, 10] \n",
      " elements = [(112, 2), (124, 4), (121, 4), (111, 2)] \n",
      "\n",
      "\n",
      "In batch 2: \n",
      " indices = [19, 16, 6, 5] \n",
      " elements = [(120, 3), (117, 3), (107, 1), (106, 1)] \n",
      "\n",
      "\n",
      "In batch 3: \n",
      " indices = [13, 3, 13, 2] \n",
      " elements = [(114, 2), (104, 0), (114, 2), (103, 0)] \n",
      "\n",
      "\n",
      "In batch 4: \n",
      " indices = [22, 0, 0, 24] \n",
      " elements = [(123, 4), (101, 0), (101, 0), (125, 4)] \n",
      "\n",
      "\n",
      "In batch 5: \n",
      " indices = [15, 21, 21, 18] \n",
      " elements = [(116, 3), (122, 4), (122, 4), (119, 3)] \n",
      "\n",
      "\n",
      "In batch 6: \n",
      " indices = [9, 7, 17, 17] \n",
      " elements = [(110, 1), (108, 1), (118, 3), (118, 3)] \n",
      "\n",
      "\n",
      " i = 6\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i, indices in enumerate(mysampler):\n",
    "    print(f\"In batch {i}: \\n indices = {indices} \\n elements = {[mydataset[i] for i in indices]} \\n\\n\")\n",
    "    \n",
    "print(f\" i = {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the sampling strategy for imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdataset = MyDataset(list(range(101,126)), [0,0,0,0,0,0, 1,1,1,1,1,1,2,2,2,2,3,3,3, 3,3,3, 4,4, 4, ])\n",
    "new_start_indices = {0 : 0, 1: 6, 2: 12, 3:16, 4:22} #index of first entry of that class\n",
    "new_num_examples = {0:6, 1:6, 2:4, 3:6, 4:3} #number of examples for each label\n",
    "\n",
    "num_classes = 5\n",
    "newsampler = ClassUniformBatchSampler(dataset=newdataset, P=2, K=2,\n",
    "                                      num_examples=new_num_examples,\n",
    "                                      start_indices=new_start_indices) #each batch has 4 elements from 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 13:46:35.462 | INFO     | __main__:__iter__:43 - k_at_a_time = defaultdict(<class 'list'>, {0: [[4, 3], [4, 2], [1, 5]], 1: [[8, 6], [9, 7], [11, 6]], 2: [[12, 15], [14, 12]], 3: [[21, 16], [21, 20], [18, 17]], 4: [[22, 22], [24, 23]]})\n",
      "2022-11-18 13:46:35.462 | INFO     | __main__:__iter__:72 - alive_classes = {0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In batch 0: \n",
      " indices = [6, 17, 18, 11] \n",
      " elements = [(107, 1), (118, 3), (119, 3), (112, 1)] \n",
      "\n",
      "\n",
      "In batch 1: \n",
      " indices = [21, 12, 14, 20] \n",
      " elements = [(122, 3), (113, 2), (115, 2), (121, 3)] \n",
      "\n",
      "\n",
      "In batch 2: \n",
      " indices = [21, 7, 9, 16] \n",
      " elements = [(122, 3), (108, 1), (110, 1), (117, 3)] \n",
      "\n",
      "\n",
      "In batch 3: \n",
      " indices = [15, 24, 23, 12] \n",
      " elements = [(116, 2), (125, 4), (124, 4), (113, 2)] \n",
      "\n",
      "\n",
      "In batch 4: \n",
      " indices = [6, 1, 8, 5] \n",
      " elements = [(107, 1), (102, 0), (109, 1), (106, 0)] \n",
      "\n",
      "\n",
      "In batch 5: \n",
      " indices = [22, 22, 2, 4] \n",
      " elements = [(123, 4), (123, 4), (103, 0), (105, 0)] \n",
      "\n",
      "\n",
      " i = 5\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i, indices in enumerate(newsampler):\n",
    "    print(f\"In batch {i}: \\n indices = {indices} \\n elements = {[newdataset[i] for i in indices]} \\n\\n\")\n",
    "    \n",
    "print(f\" i = {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1899c2cfeb0a97bb7f796d16f358d950e5c18ee1c44c1d930b588549039f22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

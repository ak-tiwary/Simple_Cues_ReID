{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to implement centerloss where we take as input a batch of features `N x d`, where `d` is the embedding dimension, and compute the loss $$L = \\frac{1}{2} \\sum_{j \\in \\text{Batch}} \\lvert\\lvert f_j - c_j \\rvert\\rvert^2$$ where $c_j$ is the learned center for the class corresponding to the training example $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenterLoss(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_dim):\n",
    "        \"\"\"Assume that the classes are 0 to num_classes-1 as usual.\"\"\"\n",
    "        self.centers = nn.Parameter(torch.empty((num_classes, embedding_dim), dtype=torch.float))\n",
    "        nn.init.xavier_normal_(self.centers)\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, features, class_labels):\n",
    "        \"\"\"Assumes features is Nxd and class labels is N\"\"\"\n",
    "        centers = self.centers[class_labels] #so centers[j] is the center associated with label j\n",
    "        return self.mse(features, centers)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3442,  0.4859, -0.0677,  0.0039,  0.0724],\n",
       "        [-0.0618, -1.0802,  0.3024, -0.5622, -1.2536],\n",
       "        [-0.4044, -0.3095, -0.0891, -0.7248,  0.0829]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Parameter(torch.empty((3,5)))\n",
    "nn.init.xavier_normal_(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3442,  0.4859, -0.0677,  0.0039,  0.0724],\n",
       "        [-0.4044, -0.3095, -0.0891, -0.7248,  0.0829],\n",
       "        [-0.0618, -1.0802,  0.3024, -0.5622, -1.2536],\n",
       "        [-0.4044, -0.3095, -0.0891, -0.7248,  0.0829]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([0,2,1,2])\n",
    "a[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1899c2cfeb0a97bb7f796d16f358d950e5c18ee1c44c1d930b588549039f22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
